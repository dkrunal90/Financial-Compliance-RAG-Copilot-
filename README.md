ğŸ’¼ Financial Compliance RAG Copilot

An AIâ€‘powered copilot for financial compliance teams that combines **Retrievalâ€‘Augmented Generation (RAG)** with a **fineâ€‘tuned NER model** to answer policy questions, highlight risky entities, and evaluate answer quality.[1]

***

## ğŸ¯ What this copilot can do

- **Ask policy questions in plain English**  
  RAGâ€‘based Q&A over your internal compliance corpus using **LlamaIndex + FAISS + Llama 3** via Ollama.[1]

- **Spot critical financial entities instantly**  
  Fineâ€‘tuned **DistilBERT** NER to tag PERSON, ORG, ACCOUNT_NUMBER and other sensitive fields from raw text or chat input.[1]

- **Measure answer quality, not just vibes**  
  BLEUâ€‘based evaluation against gold Q&A pairs so you can track how good the assistant really is over time.[1]

- **Use it however you like**  
  - Interactive **CLI** for power users  
  - **FastAPI REST API** for backend integration  
  - **Streamlit Web UI** for analysts and reviewers[1]

***

## ğŸš€ Quick start in 4 steps

### 1ï¸âƒ£ Clone and environment

```bash
git clone https://github.com/dkrunal90/Financial-Compliance-RAG-Copilot-.git
cd Financial-Compliance-RAG-Copilot-

# Create virtual environment
conda create -p venv python=3.10
conda activate ./venv

# Install dependencies
pip install -r requirements.txt
```

### 2ï¸âƒ£ Install Ollama + LLM

```bash
# Install from https://ollama.ai
ollama pull llama3.2
```

### 3ï¸âƒ£ Prepare data and models

```bash
# Generate synthetic compliance Q&A + NER data
python src/create_sample_data.py

# Fine-tune DistilBERT for financial NER (~5 minutes)
python src/ner_train.py

# Build FAISS vector index for RAG
python src/ingest_index.py
```

### 4ï¸âƒ£ Run your copilot

```bash
# Interactive CLI
python src/chat_cli.py

# REST API
python src/api.py

# Web UI
streamlit run src/app_streamlit.py
```

***

## ğŸ“Š What using it looks like

### ğŸ’¬ Chat over policies (CLI)

```text
You: ask What documents are required for KYC?

Assistant:
For KYC, you typically need:
1. Government ID (PAN/SSN/Passport)
2. Address proof
3. Recent photograph
4. Bank account details

[Answer grounded in retrieved compliance documents]
```

### ğŸ§¾ Financial NER extraction

```text
You: ner Rahul transferred money to HDFC account 1234567890

Extracted Entities:
 â€¢ Rahul        â†’ PERSON
 â€¢ HDFC         â†’ ORG
 â€¢ 1234567890   â†’ ACCOUNT_NUMBER
```

***

## ğŸ³ Oneâ€‘command Docker deploy

```bash
docker-compose up -d
```

This spins up the FastAPI backend and supporting services defined in `docker-compose.yml` so you can use the API and UI without manual setup.[1]

***

## ğŸ“‚ Project layout

```text
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ create_sample_data.py   # Generate synthetic training data
â”‚   â”œâ”€â”€ ner_train.py            # Fine-tune DistilBERT for NER
â”‚   â”œâ”€â”€ ner_infer.py            # NER inference utilities
â”‚   â”œâ”€â”€ ingest_index.py         # Build FAISS vector index for RAG
â”‚   â”œâ”€â”€ rag_chain.py            # RAG orchestration with LlamaIndex
â”‚   â”œâ”€â”€ evaluate_bleu.py        # BLEU-based answer evaluation
â”‚   â”œâ”€â”€ chat_cli.py             # CLI entrypoint
â”‚   â”œâ”€â”€ api.py                  # FastAPI REST service
â”‚   â””â”€â”€ app_streamlit.py        # Streamlit web UI
â”œâ”€â”€ data/                       # Generated sample data
â”œâ”€â”€ models/                     # Trained NER / saved checkpoints
â”œâ”€â”€ indexes/                    # Vector indexes (FAISS)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ docker-compose.yml
```


***

## ğŸ”§ Under the hood

- **NER**: DistilBERT (HuggingFace), fineâ€‘tuned for financial entities.[1]
- **Embeddings**: `sentence-transformers/all-MiniLM-L6-v2` for dense semantic search.[1]
- **Vector store**: FAISS for fast similarity search over compliance chunks.[1]
- **RAG orchestration**: LlamaIndex to wire loaders, index, retriever, and LLM together.[1]
- **LLM**: Llama 3.2 served locally via Ollama for lowâ€‘latency, private inference.[1]

***

## ğŸ“ License & ğŸ¤ Contributions

- Licensed under **MIT** â€“ use it, tweak it, ship it.[1]
- Pull requests are very welcome: new entity types, better evaluation metrics, or production hardening (auth, logging, tracing) are all great places to contribute.[1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/30658921/9063d921-4282-4257-9b0a-5065eca98c3c/README-2.md)
[2](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/30658921/230e3302-67ef-4e82-aea8-a604a64ca6ce/Krunal-Desai_AI-ML-Engineer.pdf)
[3](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/images/30658921/9f9d9777-375d-45ae-a5e0-a9350745029c/image.jpg)
